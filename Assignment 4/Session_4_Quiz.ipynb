{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Session 4_Quiz.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jofyc9OC4Qcf"
      },
      "source": [
        "#Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahBVnrNc3E0U"
      },
      "source": [
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "plt.style.use('seaborn-white')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crQSAaIz4SkA"
      },
      "source": [
        "# Read and process data. \n",
        "\n",
        "Download the file from this URL: https://drive.google.com/file/d/1UWWIi-sz9g0x3LFvkIZjvK1r2ZaCqgGS/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgOGxPDP3Wpp",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCkgewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwogICAgICBwZXJjZW50LnRleHRDb250ZW50ID0KICAgICAgICAgIGAke01hdGgucm91bmQoKHBvc2l0aW9uIC8gZmlsZURhdGEuYnl0ZUxlbmd0aCkgKiAxMDApfSUgZG9uZWA7CiAgICB9CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "4bbd3424-2aca-4440-b861-9f38447968ec"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "data = open('text.txt', 'r').read()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-744bba93-0e51-4586-b577-fcf811063131\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-744bba93-0e51-4586-b577-fcf811063131\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving text.txt to text.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeXXMLRb4kXb"
      },
      "source": [
        "Process data and calculate indices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5TKeiOp4jtl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ffea40a-684a-428b-a690-bb4f10d6f5b6"
      },
      "source": [
        "chars = list(set(data))\n",
        "data_size, X_size = len(data), len(chars)\n",
        "print(\"Corona Virus article has %d characters, %d unique characters\" %(data_size, X_size))\n",
        "char_to_idx = {ch:i for i,ch in enumerate(chars)}\n",
        "idx_to_char = {i:ch for i,ch in enumerate(chars)}"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Corona Virus article has 10223 characters, 75 unique characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4C53MB135LRY"
      },
      "source": [
        "# Constants and Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfj21ORa49Ps",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cb37488-281f-4248-9e9b-f3dbb8170088"
      },
      "source": [
        "Hidden_Layer_size = 100 #size of the hidden layer\n",
        "Time_steps = 40 # Number of time steps (length of the sequence) used for training\n",
        "learning_rate = 1e-1 # Learning Rate\n",
        "weight_sd = 0.1 #Standard deviation of weights for initialization\n",
        "z_size = Hidden_Layer_size + X_size #Size of concatenation(H, X) vector\n",
        "print(z_size)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "175\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdmJf4Du5uhb"
      },
      "source": [
        "# Activation Functions and Derivatives"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seGHei_D5FGk"
      },
      "source": [
        "def sigmoid(x): # sigmoid function\n",
        "  return (1 / (1 + np.exp(-x)))# write your code here\n",
        "\n",
        "def dsigmoid(y): # derivative of sigmoid function\n",
        "  return (sigmoid(y) * (1  - sigmoid(y)))# write your code here\n",
        "\n",
        "def tanh(x): # tanh function\n",
        "  return np.tanh(x)# write your code here\n",
        "\n",
        "def dtanh(y): # derivative of tanh\n",
        "  return (1 - np.power(np.tanh(y), 2))# write your code here"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8U2R6ggDW3oK"
      },
      "source": [
        "import math\n",
        "def truncate(f, n):\n",
        "    return math.floor(f * 10 ** n) / 10 ** n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEHHCtkEW5MF",
        "outputId": "7f40f0ba-6fc9-4311-a536-f2bc579f321b"
      },
      "source": [
        "#Quiz Question 1\n",
        "#What is the value of sigmoid(0) calculated from your code? (Answer up to 1 decimal point, e.g. 4.2 and NOT 4.29999999, no rounding off).\n",
        "print('sigmoid(0) = ', truncate(sigmoid(0), 1))\n",
        "\n",
        "#Quiz Question 2\n",
        "#What is the value of dsigmoid(sigmoid(0)) calculated from your code?? (Answer up to 2 decimal point, e.g. 4.29 and NOT 4.29999999, no rounding off).\n",
        "print('dsigmoid(sigmoid(0)) = ', truncate(dsigmoid(sigmoid(0)), 2))\n",
        "\n",
        "#Quiz Question 3\n",
        "#What is the value of tanh(dsigmoid(sigmoid(0))) calculated from your code?? (Answer up to 5 decimal point, e.g. 4.29999 and NOT 4.29999999, no rounding off).\n",
        "print('tanh(dsigmoid(sigmoid(0))) = ', truncate(tanh(dsigmoid(sigmoid(0))), 5))\n",
        "\n",
        "#Quiz Question 4\n",
        "#What is the value of dtanh(tanh(dsigmoid(sigmoid(0)))) calculated from your code?? (Answer up to 5 decimal point, e.g. 4.29999 and NOT 4.29999999, no rounding off).\n",
        "print('dtanh(tanh(dsigmoid(sigmoid(0)))) = ', truncate(dtanh(tanh(dsigmoid(sigmoid(0)))), 5))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sigmoid(0) =  0.5\n",
            "dsigmoid(sigmoid(0)) =  0.23\n",
            "tanh(dsigmoid(sigmoid(0))) =  0.23077\n",
            "dtanh(tanh(dsigmoid(sigmoid(0)))) =  0.94857\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeCvVH1v6Me-"
      },
      "source": [
        "# Quiz Question 1\n",
        "\n",
        "What is the value of sigmoid(0) calculated from  your code? (Answer up to 1 decimal point, e.g. 4.2 and NOT 4.29999999, no rounding off).\n",
        "\n",
        "# Quiz Question 2\n",
        "\n",
        "What is the value of dsigmoid(sigmoid(0)) calculated from your code?? (Answer up to 2 decimal point, e.g. 4.29 and NOT 4.29999999, no rounding off). \n",
        "\n",
        "# Quiz Question 3\n",
        "\n",
        "What is the value of tanh(dsigmoid(sigmoid(0))) calculated from your code?? (Answer up to 5 decimal point, e.g. 4.29999 and NOT 4.29999999, no rounding off).\n",
        "\n",
        "# Quiz Question 4\n",
        "\n",
        "What is the value of dtanh(tanh(dsigmoid(sigmoid(0)))) calculated from your code?? (Answer up to 5 decimal point, e.g. 4.29999 and NOT 4.29999999, no rounding off)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeSVipDu8iKE"
      },
      "source": [
        "# Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICbWNemE6LGV"
      },
      "source": [
        "class Param:\n",
        "    def __init__(self, name, value):\n",
        "      self.name = name\n",
        "      self.v = value # parameter value\n",
        "      self.d = np.zeros_like(value) # derivative\n",
        "      self.m = np.zeros_like(value) # momentum for Adagrad"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j83pZNPE8212"
      },
      "source": [
        "We use random weights with normal distribution (0, weight_sd) for  tanh  activation function and (0.5, weight_sd) for  `sigmoid`  activation function.\n",
        "\n",
        "Biases are initialized to zeros."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swHwLXOI9E7V"
      },
      "source": [
        "# LSTM \n",
        "You are making this network, please note f, i, c and o (also \"v\") in the image below:\n",
        "![alt text](http://blog.varunajayasiri.com/ml/lstm.svg)\n",
        "\n",
        "Please note that we are concatenating the old_hidden_vector and new_input."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0DBzNY-90s5"
      },
      "source": [
        "# Quiz Question 4\n",
        "\n",
        "In the class definition below, what should be size_a, size_b, and size_c? ONLY use the variables defined above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFuHhqVq6Wge"
      },
      "source": [
        "size_a = Hidden_Layer_size# write your code here\n",
        "size_b = z_size# write your code here\n",
        "size_c = X_size# write your code here\n",
        "\n",
        "class Parameters:\n",
        "    def __init__(self):\n",
        "        self.W_f = Param('W_f', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_f = Param('b_f', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_i = Param('W_i', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_i = Param('b_i', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_C = Param('W_C', np.random.randn(size_a, size_b) * weight_sd)\n",
        "        self.b_C = Param('b_C', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_o = Param('W_o', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_o = Param('b_o', np.zeros((size_a, 1)))\n",
        "\n",
        "        #For final layer to predict the next character\n",
        "        self.W_v = Param('W_v', np.random.randn(X_size, size_a) * weight_sd)\n",
        "        self.b_v = Param('b_v', np.zeros((size_c, 1)))\n",
        "        \n",
        "    def all(self):\n",
        "        return [self.W_f, self.W_i, self.W_C, self.W_o, self.W_v,\n",
        "               self.b_f, self.b_i, self.b_C, self.b_o, self.b_v]\n",
        "        \n",
        "parameters = Parameters()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzmfGLZt_xVs"
      },
      "source": [
        "Look at these operations which we'll be writing:\n",
        "\n",
        "**Concatenation of h and x:**\n",
        "\n",
        "$z\\:=\\:\\left[h_{t-1},\\:x\\right]$\n",
        "\n",
        "$f_t=\\sigma\\left(W_f\\cdot z\\:+\\:b_f\\:\\right)$\n",
        "\n",
        "$i_i=\\sigma\\left(W_i\\cdot z\\:+\\:b_i\\right)$\n",
        "\n",
        "$\\overline{C_t}=\\tanh\\left(W_C\\cdot z\\:+\\:b_C\\right)$\n",
        "\n",
        "$C_t=f_t\\ast C_{t-1}+i_t\\ast \\overline{C}_t$\n",
        "\n",
        "$o_t=\\sigma\\left(W_o\\cdot z\\:+\\:b_i\\right)$\n",
        "\n",
        "$h_t=o_t\\ast\\tanh\\left(C_t\\right)$\n",
        "\n",
        "**Logits:**\n",
        "\n",
        "$v_t=W_v\\cdot h_t+b_v$\n",
        "\n",
        "**Softmax:**\n",
        "\n",
        "$\\hat{y}=softmax\\left(v_t\\right)$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bUkseNnDott"
      },
      "source": [
        "def forward(x, h_prev, C_prev, p = parameters):\n",
        "    assert x.shape == (X_size, 1)\n",
        "    assert h_prev.shape == (Hidden_Layer_size, 1)\n",
        "    assert C_prev.shape == (Hidden_Layer_size, 1)\n",
        "\n",
        "    z = np.row_stack((h_prev, x))\n",
        "    f = sigmoid(np.dot(p.W_f.v,z) + p.b_f.v) \n",
        "    i = sigmoid(np.dot(p.W_i.v,z) + p.b_i.v)\n",
        "    C_bar = tanh(np.dot(p.W_C.v,z) + p.b_C.v)\n",
        "\n",
        "    C = (f*C_prev) + (i*C_bar)\n",
        "    o = sigmoid(np.dot(p.W_o.v,z) + p.b_o.v)\n",
        "    h = o*tanh(C)\n",
        "    #print(o.shape,C.shape,h.shape)\n",
        "\n",
        "    v = np.dot(p.W_v.v,h) + p.b_v.v\n",
        "    y = np.exp(v)/np.sum(np.exp(v)) #softmax\n",
        "    \n",
        "    \n",
        "\n",
        "    return z, f, i, C_bar, C, o, h, v, y"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZrDhZIjFpdI"
      },
      "source": [
        "You must finish the function above before you can attempt the questions below. \n",
        "\n",
        "# Quiz Question 5\n",
        "\n",
        "What is the output of 'print(len(forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)), parameters)))'?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7q65YhHFxRLl",
        "outputId": "ddc80c5b-8bce-499a-e533-44eefb2a934e"
      },
      "source": [
        "print(len(forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)), parameters)))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XV-YVl_GGiX8"
      },
      "source": [
        "# Quiz Question 6. \n",
        "\n",
        "Assuming you have fixed the forward function, run this command: \n",
        "z, f, i, C_bar, C, o, h, v, y = forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)))\n",
        "\n",
        "Now, find these values:\n",
        "\n",
        "\n",
        "1.   print(z.shape)\n",
        "2.   print(np.sum(z))\n",
        "3.   print(np.sum(f))\n",
        "\n",
        "Copy and paste exact values you get in the logs into the quiz.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GvKVWmTDt3H"
      },
      "source": [
        "z, f, i, C_bar, C, o, h, v, y = forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8BHPGRxxokG",
        "outputId": "142e3ca8-0c86-47ee-f540-ebd9ae4b9410"
      },
      "source": [
        "print(z.shape)\n",
        "print(np.sum(z))\n",
        "print(np.sum(f))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(175, 1)\n",
            "0.0\n",
            "50.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeSvhkqwILsG"
      },
      "source": [
        "# Backpropagation\n",
        "\n",
        "Here we are defining the backpropagation. It's too complicated, here is the whole code. (Please note that this would work only if your earlier code is perfect)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIa1jUZiGPmF"
      },
      "source": [
        "def backward(target, dh_next, dC_next, C_prev,\n",
        "             z, f, i, C_bar, C, o, h, v, y,\n",
        "             p = parameters):\n",
        "    \n",
        "    assert z.shape == (X_size + Hidden_Layer_size, 1)\n",
        "    assert v.shape == (X_size, 1)\n",
        "    assert y.shape == (X_size, 1)\n",
        "    \n",
        "    for param in [dh_next, dC_next, C_prev, f, i, C_bar, C, o, h]:\n",
        "        assert param.shape == (Hidden_Layer_size, 1)\n",
        "        \n",
        "    dv = np.copy(y)\n",
        "    dv[target] -= 1\n",
        "\n",
        "    p.W_v.d += np.dot(dv, h.T)\n",
        "    p.b_v.d += dv\n",
        "\n",
        "    dh = np.dot(p.W_v.v.T, dv)        \n",
        "    dh += dh_next\n",
        "    do = dh * tanh(C)\n",
        "    do = dsigmoid(o) * do\n",
        "    p.W_o.d += np.dot(do, z.T)\n",
        "    p.b_o.d += do\n",
        "\n",
        "    dC = np.copy(dC_next)\n",
        "    dC += dh * o * dtanh(tanh(C))\n",
        "    dC_bar = dC * i\n",
        "    dC_bar = dtanh(C_bar) * dC_bar\n",
        "    p.W_C.d += np.dot(dC_bar, z.T)\n",
        "    p.b_C.d += dC_bar\n",
        "\n",
        "    di = dC * C_bar\n",
        "    di = dsigmoid(i) * di\n",
        "    p.W_i.d += np.dot(di, z.T)\n",
        "    p.b_i.d += di\n",
        "\n",
        "    df = dC * C_prev\n",
        "    df = dsigmoid(f) * df\n",
        "    p.W_f.d += np.dot(df, z.T)\n",
        "    p.b_f.d += df\n",
        "\n",
        "    dz = (np.dot(p.W_f.v.T, df)\n",
        "         + np.dot(p.W_i.v.T, di)\n",
        "         + np.dot(p.W_C.v.T, dC_bar)\n",
        "         + np.dot(p.W_o.v.T, do))\n",
        "    dh_prev = dz[:Hidden_Layer_size, :]\n",
        "    dC_prev = f * dC\n",
        "    \n",
        "    return dh_prev, dC_prev"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tnc7WpRkIU5S"
      },
      "source": [
        "# Forward and Backward Combined Pass\n",
        "\n",
        "Let's first clear the gradients before each backward pass"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJWoC3U1ITf8"
      },
      "source": [
        "def clear_gradients(params = parameters):\n",
        "    for p in params.all():\n",
        "        p.d.fill(0)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XN93UnjIgmA"
      },
      "source": [
        "Clip gradients to mitigate exploding gradients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LTsublxIfFl"
      },
      "source": [
        "def clip_gradients(params = parameters):\n",
        "    for p in params.all():\n",
        "        np.clip(p.d, -1, 1, out=p.d)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7XUpDTWIl_Y"
      },
      "source": [
        "Calculate and store the values in forward pass. Accumulate gradients in backward pass and clip gradients to avoid exploding gradients.\n",
        "\n",
        "input, target are list of integers, with character indexes.\n",
        "h_prev is the array of initial h at  h−1  (size H x 1)\n",
        "C_prev is the array of initial C at  C−1  (size H x 1)\n",
        "Returns loss, final  hT  and  CT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQNxjTuZIia_"
      },
      "source": [
        "def forward_backward(inputs, targets, h_prev, C_prev):\n",
        "    global paramters\n",
        "    \n",
        "    # To store the values for each time step\n",
        "    x_s, z_s, f_s, i_s,  = {}, {}, {}, {}\n",
        "    C_bar_s, C_s, o_s, h_s = {}, {}, {}, {}\n",
        "    v_s, y_s =  {}, {}\n",
        "    \n",
        "    # Values at t - 1\n",
        "    h_s[-1] = np.copy(h_prev)\n",
        "    C_s[-1] = np.copy(C_prev)\n",
        "    \n",
        "    loss = 0\n",
        "    # Loop through time steps\n",
        "    assert len(inputs) == Time_steps\n",
        "    for t in range(len(inputs)):\n",
        "        x_s[t] = np.zeros((X_size, 1))\n",
        "        x_s[t][inputs[t]] = 1 # Input character\n",
        "        \n",
        "        (z_s[t], f_s[t], i_s[t],\n",
        "        C_bar_s[t], C_s[t], o_s[t], h_s[t],\n",
        "        v_s[t], y_s[t]) = \\\n",
        "            forward(x_s[t], h_s[t - 1], C_s[t - 1]) # Forward pass\n",
        "            \n",
        "        loss += -np.log(y_s[t][targets[t], 0]) # Loss for at t\n",
        "        \n",
        "    clear_gradients()\n",
        "\n",
        "    dh_next = np.zeros_like(h_s[0]) #dh from the next character\n",
        "    dC_next = np.zeros_like(C_s[0]) #dh from the next character\n",
        "\n",
        "    for t in reversed(range(len(inputs))):\n",
        "        # Backward pass\n",
        "        dh_next, dC_next = \\\n",
        "            backward(target = targets[t], dh_next = dh_next,\n",
        "                     dC_next = dC_next, C_prev = C_s[t-1],\n",
        "                     z = z_s[t], f = f_s[t], i = i_s[t], C_bar = C_bar_s[t],\n",
        "                     C = C_s[t], o = o_s[t], h = h_s[t], v = v_s[t],\n",
        "                     y = y_s[t])\n",
        "\n",
        "    clip_gradients()\n",
        "        \n",
        "    return loss, h_s[len(inputs) - 1], C_s[len(inputs) - 1]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcy5u_vRItkV"
      },
      "source": [
        "# Sample the next character"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8SrtJiwIsSm"
      },
      "source": [
        "def sample(h_prev, C_prev, first_char_idx, sentence_length):\n",
        "    x = np.zeros((X_size, 1))\n",
        "    x[first_char_idx] = 1\n",
        "\n",
        "    h = h_prev\n",
        "    C = C_prev\n",
        "\n",
        "    indexes = []\n",
        "    \n",
        "    for t in range(sentence_length):\n",
        "        _, _, _, _, C, _, h, _, p = forward(x, h, C)\n",
        "        idx = np.random.choice(range(X_size), p=p.ravel())\n",
        "        x = np.zeros((X_size, 1))\n",
        "        x[idx] = 1\n",
        "        indexes.append(idx)\n",
        "\n",
        "    return indexes"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiWFaWLNIx_L"
      },
      "source": [
        "# Training (Adagrad)\n",
        "\n",
        "Update the graph and display a sample output\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENQYU-7AIw0t"
      },
      "source": [
        "def update_status(inputs, h_prev, C_prev):\n",
        "    #initialized later\n",
        "    global plot_iter, plot_loss\n",
        "    global smooth_loss\n",
        "    \n",
        "    # Get predictions for 200 letters with current model\n",
        "\n",
        "    sample_idx = sample(h_prev, C_prev, inputs[0], 200)\n",
        "    txt = ''.join(idx_to_char[idx] for idx in sample_idx)\n",
        "\n",
        "    # Clear and plot\n",
        "    plt.plot(plot_iter, plot_loss)\n",
        "    display.clear_output(wait=True)\n",
        "    plt.show()\n",
        "\n",
        "    #Print prediction and loss\n",
        "    print(\"----\\n %s \\n----\" % (txt, ))\n",
        "    print(\"iter %d, loss %f\" % (iteration, smooth_loss))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACXcASJuI73a"
      },
      "source": [
        "# Update Parameters\n",
        "\n",
        "\\begin{align}\n",
        "\\theta_i &= \\theta_i - \\eta\\frac{d\\theta_i}{\\sum dw_{\\tau}^2} \\\\\n",
        "d\\theta_i &= \\frac{\\partial L}{\\partial \\theta_i}\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bR08TvcjI4Pf"
      },
      "source": [
        "def update_paramters(params = parameters):\n",
        "    for p in params.all():\n",
        "        p.m += p.d * p.d # Calculate sum of gradients\n",
        "        #print(learning_rate * dparam)\n",
        "        p.v += -(learning_rate * p.d / np.sqrt(p.m + 1e-8))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "La9vyJ6RJLFK"
      },
      "source": [
        "To delay the keyboard interrupt to prevent the training from stopping in the middle of an iteration\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVDHbMb7JNGT"
      },
      "source": [
        "# Exponential average of loss\n",
        "# Initialize to a error of a random model\n",
        "smooth_loss = -np.log(1.0 / X_size) * Time_steps\n",
        "\n",
        "iteration, pointer = 0, 0\n",
        "\n",
        "# For the graph\n",
        "plot_iter = np.zeros((0))\n",
        "plot_loss = np.zeros((0))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HF6vS0VWJqsS"
      },
      "source": [
        "# Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQyNSL0iJOxH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "3030b810-d332-43c5-e157-7c99949ba403"
      },
      "source": [
        "iter = 50000\n",
        "while iter > 0:\n",
        "  # Reset\n",
        "  if pointer + Time_steps >= len(data) or iteration == 0:\n",
        "      g_h_prev = np.zeros((Hidden_Layer_size, 1))\n",
        "      g_C_prev = np.zeros((Hidden_Layer_size, 1))\n",
        "      pointer = 0\n",
        "\n",
        "\n",
        "  inputs = ([char_to_idx[ch] \n",
        "              for ch in data[pointer: pointer + Time_steps]])\n",
        "  targets = ([char_to_idx[ch] \n",
        "              for ch in data[pointer + 1: pointer + Time_steps + 1]])\n",
        "\n",
        "  loss, g_h_prev, g_C_prev = \\\n",
        "      forward_backward(inputs, targets, g_h_prev, g_C_prev)\n",
        "  smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
        "\n",
        "  # Print every hundred steps\n",
        "  if iteration % 100 == 0:\n",
        "      update_status(inputs, g_h_prev, g_C_prev)\n",
        "\n",
        "  update_paramters()\n",
        "\n",
        "  plot_iter = np.append(plot_iter, [iteration])\n",
        "  plot_loss = np.append(plot_loss, [loss])\n",
        "\n",
        "  pointer += Time_steps\n",
        "  iteration += 1\n",
        "  iter = iter -1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "----\n",
            " O d\n",
            "tun.anoucruvwicnl iosaev th  a u y\n",
            "ron en iSh eermaure udpfyts eoNe \"e steoch gd arhooc cr. eosndsnl  uteips o;uM 4oh otgAC s are  i ayaiiam'hs S  n  ooylBsrhrsu coni-eCn pes8 ch a h eyas sohornl  \n",
            "----\n",
            "iter 29900, loss 121.758914\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apJp8WUGyoAn"
      },
      "source": [
        "\n",
        "     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AKpa1BGOItQ"
      },
      "source": [
        "# Quiz Question 7. \n",
        "\n",
        "Run the above code for 50000 iterations making sure that you have 100 hidden layers and time_steps is 40. What is the loss value you're seeing?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQeyiyUPO02O"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}